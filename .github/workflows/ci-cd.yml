name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  # Step 1: Create EKS Cluster
  create-eks-cluster:
    name: Create EKS Cluster
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Set up AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Install eksctl
        run: |
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_linux_amd64.tar.gz"
          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_linux_amd64.tar.gz"
    
          # Extract the tarball to /tmp directory
          tar -xzvf eksctl_linux_amd64.tar.gz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin

      - name: Create EKS Cluster
        run: |
          if eksctl get cluster --name my-new-cluster --region ${{ secrets.AWS_REGION }}; then
              echo "Cluster exists, updating..."
          # Scale the node group to update instances
            eksctl scale nodegroup --name eksctl-my-new-cluster-nodegroup --cluster my-new-cluster --region ${{ secrets.AWS_REGION }} --nodes 3 --nodes-min 1 --nodes-max 5

          echo "Waiting for new nodes to be ready..."
          sleep 60

          else
          echo "Cluster does not exist, creating a new cluster..."

          eksctl create cluster \
            --name my-new-cluster \
            --region ${{ secrets.AWS_REGION }}
            --nodegroup-name my-nodegroup \
            --node-type t3.medium \
            --nodes 3 \
            --nodes-min 1 \
            --nodes-max 5 \
            --managed
          fi

      - name: Update kubeconfig for EKS
        run: aws eks update-kubeconfig --name my-new-cluster --region ${{ secrets.AWS_REGION }}

  # Step 2: SonarQube Analysis
  sonarqube:
    name: SonarQube
    runs-on: ubuntu-latest
    needs: create-eks-cluster
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: SonarQube Scan
        uses: SonarSource/sonarqube-scan-action@v4
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: "https://sonarcloud.io"

  # Step 2: Backend Build & Deploy (Only if SonarQube Passes)
  backend:
    needs: [sonarqube]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install Dependencies (Backend)
        working-directory: ./backend
        run: npm install

      - name: Run Backend Tests
        working-directory: ./backend
        env:
          NODE_ENV: test
          CI: true
        run: npm test

      - name: Build Backend Docker Image
        run: docker build -t cicd-full-cycle-backend ./backend

      - name: Tag Backend Image for Scanning
        run: docker tag cicd-full-cycle-backend cicd-full-cycle-backend:latest

      - name: Trivy Vulnerability Scan (Backend)
        run: docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy:latest image cicd-full-cycle-backend:latest

      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Tag & Push Backend Docker Image
        run: |
          docker tag cicd-full-cycle-backend docker.io/akash3103/cicd-backend:latest
          docker push docker.io/akash3103/cicd-backend:latest

  # Step 3: Frontend Build & Deploy (Only if SonarQube Passes)
  frontend:
    needs: [sonarqube]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install Dependencies (Frontend)
        working-directory: ./frontend
        run: npm install

      - name: Run Frontend Tests
        working-directory: ./frontend
        env:
          NODE_ENV: test
          CI: true
        run: npm test

      - name: Build Frontend
        working-directory: ./frontend
        run: npm run build

      - name: Build Frontend Docker Image
        run: docker build -t cicd-full-cycle-frontend ./frontend

      - name: Tag Frontend Image for Scanning
        run: docker tag cicd-full-cycle-frontend cicd-full-cycle-frontend:latest

      - name: Trivy Vulnerability Scan (Frontend)
        run: docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy:latest image cicd-full-cycle-frontend:latest

      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Tag & Push Frontend Docker Image
        run: |
          docker tag cicd-full-cycle-frontend docker.io/akash3103/cicd-frontend:latest
          docker push docker.io/akash3103/cicd-frontend:latest
  # Step 4: Deploy to AWS EKS
  deploy:
    name: Deploy to Kubernetes (EKS)
    runs-on: ubuntu-latest
    needs: [backend, frontend]
    steps:
      - name: Checkout Repository  # This ensures the YAML files exist
        uses: actions/checkout@v3

      # Configure AWS credentials for EKS deployment
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      # Update kubeconfig so kubectl can access your EKS cluster
      - name: Update kubeconfig for EKS
        run: aws eks update-kubeconfig --name my-new-cluster --region ${{ secrets.AWS_REGION }}
  
  production-deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy]
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      # Configure AWS credentials for production deployment (if different, you can adjust here)
      - name: Configure AWS Credentials for Production
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
          
      # Update kubeconfig for production (if production cluster is the same as dev, otherwise adjust)
      - name: Update kubeconfig for Production
        run: aws eks update-kubeconfig --name my-new-cluster --region ${{ secrets.AWS_REGION }}

      # Deploy backend and frontend manifests
      - name: Deploy Backend Manifests
        run: |
          kubectl apply -f k8s/backend-deployment.yaml --validate=false
          kubectl apply -f k8s/backend-service.yaml --validate=false

      - name: Deploy Frontend Manifests
        run: |
          kubectl apply -f k8s/frontend-deployment.yaml --validate=false
          kubectl apply -f k8s/frontend-service.yaml --validate=false
  # Step 6: Cleanup
  cleanup:
    needs: [backend, frontend]
    runs-on: ubuntu-latest
    steps:
      - name: Clean up Docker images
        run: docker system prune -f
